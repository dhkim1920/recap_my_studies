# Apache Kafka 기본 개념 정리  

## Apache Kafka란?  
Apache Kafka는 **분산 스트리밍 플랫폼**으로, 실시간 데이터 스트리밍을 처리하고 관리하는 오픈 소스 프레임워크  
대용량 데이터를 높은 처리 속도로 저장, 처리, 전송할 수 있도록 설계됨

## Kafka의 특징  
- **높은 처리량**: 초당 수백만 건의 메시지를 처리할 수 있는 고성능  
- **확장성**: 클러스터를 통해 쉽게 확장 가능  
- **내결함성**: 데이터 복제와 다중 브로커 구성을 통해 안정성 확보  
- **영구 저장**: 데이터를 디스크에 저장하여 장애 시에도 복구 가능  
- **실시간 데이터 처리**: 데이터 스트림을 실시간으로 수집, 처리  

## Kafka 아키텍처  

| 구성 요소        | 설명                                                       |
|---------------|------------------------------------------------------------|
| **Producer**   | 데이터를 Kafka로 전송하는 클라이언트                        |
| **Broker**     | Kafka 서버로, 데이터를 저장하고 관리                        |
| **Topic**      | 메시지를 저장하는 논리적 개념으로, 특정 주제의 데이터 스트림 |
| **Partition**  | 하나의 Topic을 여러 개로 나눠 병렬 처리 성능 향상             |
| **Consumer**   | Kafka에서 데이터를 읽어오는 클라이언트                      |
| **Consumer Group** | 여러 Consumer가 협력하여 메시지를 병렬로 처리              |
| **Zookeeper**  | 클러스터 메타데이터 관리 및 Broker의 상태 모니터링           |

## Kafka의 리더-팔로워 구조  
Kafka의 파티션은 하나의 Leader와 여러 개의 Follower로 구성됨  
리더가 파티션의 **읽기/쓰기 요청을 처리**하고, 팔로워는 리더의 데이터를 복제하여 **데이터 일관성**을 유지함  

### 리더-팔로워 동작 방식  
1. 파티션당 하나의 리더와 여러 팔로워가 존재  
2. Producer와 Consumer는 리더를 통해 데이터를 송수신  
3. 팔로워는 주기적으로 리더의 데이터를 복제하여 **동기화** 유지  
4. 리더 장애 발생 시, 팔로워 중 하나가 **새로운 리더로 승격**되어 역할을 이어감  

### 리더-팔로워 구조의 장점  
- **데이터 안정성**: 복제본을 통해 장애 발생 시에도 데이터 복구 가능  
- **고가용성**: 리더 장애 시 팔로워를 승격하여 서비스 중단 방지  
- **부하 분산**: 리더-팔로워 간 데이터 복제를 통해 읽기 작업을 여러 노드에서 수행 가능  

## Kafka 데이터 흐름  
1. **데이터 전송**: Producer가 데이터를 특정 Topic으로 전송  
2. **데이터 저장**: Topic이 여러 개의 Partition으로 나뉘어 데이터 분산 저장  
3. **리더-팔로워 처리**: 파티션의 리더가 데이터를 처리하고, 팔로워가 복제하여 일관성 유지  
4. **Broker 저장**: 각 Partition은 Broker에 저장되어 복제본으로 관리  
5. **데이터 소비**: Consumer가 리더로부터 데이터를 가져와 처리  
6. **오프셋 관리**: 각 Consumer는 데이터를 읽은 위치를 Offset으로 관리하여 중복 처리 방지  

## Kafka 파티션과 컨슈머 그룹 관계  

### 파티션 수 < 컨슈머 수  
- 일부 컨슈머가 할당되지 않아 유휴 상태 발생  
- 리소스 낭비 문제  
- 컨슈머 인스턴스를 늘려도 처리 성능이 향상되지 않음  

### 파티션 수 > 컨슈머 수  
- 하나의 컨슈머가 여러 파티션을 처리하여 부하 집중  
- 처리 속도 저하와 성능 불균형 문제  
- 특정 컨슈머에 과부하가 걸려 장애 발생 가능성 증가  

## 최적 설계 방안  
- 파티션 수를 컨슈머 수와 동일하게 설정하여 자원 활용 최적화  
- 확장 시 파티션 수와 컨슈머 수를 비례하여 증가  
- 컨슈머 수가 파티션 수를 초과하지 않도록 관리  

## 파티션 수가 많을 경우
### 파일 핸들러 낭비
- 각 partition은 broker의 디렉토리와 매핑 되므로 Kafka는 많은 파일 핸들러가 필요 -> 리소스 낭비
### 장애 복구 시간 증가
- partition은 leader와 follower로 구분되며 오직 leader만 read/write를 수행
- 따라서 장애 시 broker controller는 각 파티션 별 leader를 새로 선출 해야함, partition이 많으므로 오래걸림
- 또한 broker controller가 다운될 경우, 다른 broker가 controller로 승격되고 zookeeper는 모든 partition 메타데이터를 읽어야함

## Kafka Offset

Kafka의 Offset은 Kafka 토픽 내 파티션에서 메시지의 위치를 나타내는 고유한 숫자임
Offset은 각 파티션마다 독립적으로 증가하며, 메시지가 추가될 때마다 증가함

### Offset의 특징
1. **고유성**: 각 파티션 내에서만 고유하며, 다른 파티션과는 독립적임  
2. **순차 증가**: 메시지가 추가될 때마다 0부터 시작하여 순차적으로 증가함  
3. **컨슈머 그룹 관리**: 각 컨슈머 그룹은 자신이 마지막으로 읽은 Offset을 커밋하여, 이후부터 이어서 읽을 수 있도록 함  

### Offset의 관리
1. **자동 커밋**: 컨슈머가 주기적으로 Offset을 자동으로 커밋하도록 설정, 간단하지만 중복 처리 또는 데이터 손실이 발생할 수 있다.
2. **수동 커밋**: 명시적으로 메서드를 호출하여 처리 완료된 Offset만 커밋할수 있으며 안정적이지만 복잡도가 증가한다.  

### Offset 관리 전략
1. **Earliest**: 컨슈머는 가장 처음 메시지부터 소비하게 된다. 이전에 커밋된 Offset이 없을 경우에만 적용됨
   - 즉, 재처리 
2. **Latest**: 컨슈머는 가장 최근 메시지부터 소비하게 된다. 이전에 커밋된 Offset이 없을 경우에만 적용됨  
3. **None**: 이전에 커밋된 Offset이 없을 경우 예외를 발생시킴  

#### ※ 이미 오프셋이 커밋되어 있는데 강제로 처음부터 읽고 싶다!
- consumer group ID를 변경
- KafkaConsumer의 seek() 메서드 사용하여 위치 지정
- kafka-consumer-groups.sh 명령어로 오프셋을 지정

### Offset 관련 문제점
1. **중복 처리**: 자동 커밋을 사용할 경우, 컨슈머가 메시지를 처리하기 전에 Offset이 커밋될 수 있으므로, 장애 발생 시 동일한 메시지를 다시 처리하게 되어 중복 처리가 발생할 수 있음
   - 수동 커밋으로 해결 가능하다.
2. **데이터 손실**: 수동 커밋을 사용할 경우, 커밋이 완료되기 전에 컨슈머가 중단되면 이미 읽은 메시지의 Offset이 저장되지 않아 해당 메시지를 다시 처리하지 못하고 데이터 손실이 발생할 수 있음
   - 수동 커밋일 경우 callback을 확인하여 재시도 할수도 있다.
   - Kafka Consumer + Producer 조합에서 Transactional 모드 활성화 
     <br>읽기, 처리, 기록, 오프셋 커밋을 하나의 트랜잭션으로 묶음
     <br>(이건 나중에 자세히 다룰 예정)


## Kafka Lag
Kafka lag은 **Consumer가 최신 메시지를 얼마나 따라잡지 못하고 뒤처져 있는가를 나타내는 지표** 
→ 즉, **처리되지 않은 메시지 수**

### Lag 계산식
```Lag = Log End Offset - Current Offset```
- **Log End Offset**: 브로커에 저장된 가장 최신 메시지의 오프셋  
- **Current Offset**: 컨슈머가 마지막으로 읽은 메시지의 오프셋

### Lag 값에 따른 의미
- `Lag = 0`: 실시간에 가깝게 잘 처리되고 있는 상태  
- `Lag` 지속 증가: 컨슈머가 처리 속도를 못 따라가고 있어 병목 또는 장애 가능성 존재

### Kafka lag이 0인데도 메시지 지연이 발생하는 이유
**오프셋 커밋 시점과 실제 처리 시점의 불일치**로 인해 lag 지표가 실제 상태를 반영하지 못할 수 있음

#### 1. 처리 전에 오프셋을 커밋하는 경우
- 컨슈머가 메시지를 처리하기 전에 오프셋을 먼저 커밋하면 Kafka는 해당 메시지를 이미 소비된 것으로 간주함  
- lag은 0으로 보이지만 내부 처리 로직은 여전히 진행 중일 수 있음  
  → 정확한 커밋 타이밍이 중요

#### 2. 비동기 처리 및 내부 큐 적체
- 비동기 처리 구조에서는 메시지가 큐에만 등록되고 오프셋이 커밋되는 경우가 있음  
- 외부에선 lag가 없다고 보이지만 실제로는 큐에 쌓여 지연 발생  
  → Kafka lag 외에도 내부 처리 상태 모니터링이 필요

#### 대응 방안
- `enable.auto.commit=false` 설정 후, 처리 완료 시점에 오프셋 커밋  
- 처리량, 지연 시간, 내부 큐 상태 등 지표 병행 모니터링
