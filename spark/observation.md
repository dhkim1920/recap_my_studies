# Spark observe는 효율적인가?

## Spark observe (Observation 기반)
- Spark 3.0에서 도입된 기능으로, 데이터가 흐르는 과정에서 지표를 수집한다.
- 기존의 `df.count()` 방식은 데이터를 한 번 더 읽는 **추가 Job**을 발생시키지만, `observe`는 단일 Action 내에서 지표를 처리한다.

## 주요 특징
- **성능 최적화:** 별도의 데이터 스캔이나 네트워크 I/O 없이, Executor가 메모리에서 데이터를 처리할 때 카운팅을 병행하므로 **오버헤드가 거의 없다고한다.**
- **데이터 정확성:** `Observation` 객체는 Action(예: `write`, `collect`)이 **성공적으로 완료된 직 후**에만 결과를 반환한다.
- **다중 지표 수집:** 한 번의 실행으로 `count`, `sum`, `max` 등 여러 집계 지표를 동시에 안전하게 얻을 수 있다.

## 주의사항 및 한계
- **위치 의존성:** `observe` 메서드가 호출된 시점의 데이터를 기준으로 집계한다. 따라서 `filter`나 `join` 뒤에 배치해야 실제 저장되는 로우 수와 일치한다. (이게 가장 중요해 보임, 위치에 따라 로우 수가 달라지므로)
- **실험적 상태 아님:** 안정화되어 운영 환경에서 권장되는 방식
- **단일 Action 귀속:** 하나의 `Observation` 객체는 하나의 Action에 대해서만 유효하다. 동일 객체로 여러 번 Action을 수행하면 지표가 덮어씌워지거나 비정상적인 값이 나올 수 있다.

## 결론

- **JDBC Read/Write 시 로우 카운팅에 가장 효율적인 도구**
- `df.count()`를 따로 호출하여 DB에 부하를 두 번 주는 방식보다 **성능과 정확도 측면에서 월등히 유리**

## observe vs count() 성능을 비교해보자

JDBC에서 1억 건의 데이터를 읽어 Parquet으로 저장한 후 실제 저장된 로우 수를 로그로 남기는 시나리오 기준이다.

### 성능 비교 결과

| 지표 | `df.count()` 사용 시 | `observe()` 사용 시 |
| --- | --- | --- |
| **실행 Job 수** | 2개 (Write Job + Count Job) | **1개 (Write Job)** |
| **데이터 스캔** | DB를 두 번 조회 (Double Read) | **DB를 한 번만 조회 (Single Read)** |
| **네트워크 부하** | 높음 (전체 데이터를 다시 로드) | **거의 없음 (Flowing 데이터 집계)** |
| **실행 시간** | 약 1.8x ~ 2x 느림 | **최적 (Action 시간과 거의 동일)** |

### 분석 요약

- 왜 count가 더 느릴까? 
> `df.count()`는 독립적인 Action이므로 전체 실행 계획(DAG)을 처음부터 다시 실행해야 하지만, `observe`는 이미 실행 중인 파이프라인 내부의 Accumulator를 이용하기 때문
- **Best Practice:** 로그나 모니터링 목적으로 로우 카운트가 필요하다면 무조건 `observe`를 사용하여 불필요한 Job 발생을 억제하자.
