# Hadoop 기본 개념 정리

## Apache Hadoop이란?
- 대규모 데이터를 **분산 저장** 및 **병렬 처리**할 수 있는 오픈 소스 프레임워크  
- 저비용 하드웨어를 이용하여 대량 데이터를 저장하고 처리

## Hadoop 구성 요소

| 구성 요소         | 설명                                                                 |
|------------------|-----------------------------------------------------------------------|
| **HDFS**          | 대용량 데이터 분산 저장 파일 시스템                                   |
| **YARN**          | 클러스터 자원 관리 및 작업 스케줄링                                    |
| **MapReduce**     | 데이터 병렬 처리 모델                                                 |
| **Hadoop Common** | 하둡에서 공통으로 사용되는 라이브러리와 유틸리티                       |


### 1. HDFS (Hadoop Distributed File System)
- 대용량 데이터를 여러 노드에 **분산 저장**  
- **블록 기반 저장**: 기본적으로 128MB 크기의 블록 단위로 저장  
- **마스터-슬레이브 구조**  
  - **NameNode**: 메타데이터 관리 (파일 이름, 블록 위치 등)  
  - **DataNode**: 실제 데이터 블록 저장  
- **복제 정책**: 기본 복제 수는 3으로, 데이터 안정성 확보  
- **내결함성**: 노드 장애 시 복제본을 통해 데이터 복구  

#### HDFS 동작 흐름
1. 사용자가 데이터를 업로드하면 **NameNode**가 메타데이터를 관리  
2. 데이터가 여러 블록으로 나뉘어 **DataNode**에 분산 저장  
3. 복제본을 여러 노드에 저장하여 **데이터 안정성** 보장  

### 2. YARN (Yet Another Resource Negotiator)
- 클러스터 리소스를 **관리 및 할당**  
- 다양한 컴퓨팅 프레임워크와 연동하여 **리소스 효율성**을 극대화  

#### YARN 구성 요소

| 구성 요소             | 설명                                                                                   |
|----------------------|-----------------------------------------------------------------------------------------|
| **ResourceManager**  | 클러스터 전체 리소스 관리 및 스케줄링                                                    |
| **NodeManager**      | 각 노드의 리소스를 관리하며, 컨테이너(Container)를 실행                                      |
| **ApplicationMaster**| 애플리케이션 별로 실행되며, 작업을 계획하고 관리                                         |

#### YARN 동작 흐름
1. 애플리케이션 제출 -> **ResourceManager**가 **ApplicationMaster**를 할당  
2. **ApplicationMaster**가 작업을 분할하여 **NodeManager**에게 실행 요청  
3. 작업 수행 후 결과를 **ApplicationMaster**에게 전달  
4. **ApplicationMaster**가 작업 완료 상태를 **ResourceManager**에 보고  

### 3. MapReduce
- 대용량 데이터 처리를 위한 **병렬 처리 모델**  
- **Map 단계**: 입력 데이터를 Key-Value 형태로 변환  
- **Shuffle 단계**: 같은 Key를 가진 데이터를 모아서 정렬  
- **Reduce 단계**: 모인 데이터를 처리하여 최종 결과 생성  

#### MapReduce 작업 흐름
1. **Input Split**: 입력 데이터를 여러 청크로 분할  
2. **Map 단계**: 각 청크를 Key-Value 형태로 변환  
3. **Shuffle 단계**: 동일한 Key를 가진 데이터를 모아 정렬  
4. **Reduce 단계**: 모인 데이터를 처리하여 결과 출력  
5. **Output**: 처리된 데이터를 HDFS에 저장  

---

### Hadoop과 Spark의 비교

| 항목         | Hadoop                                      | Spark                                                     |
|-------------|---------------------------------------------|-----------------------------------------------------------|
| 데이터 처리  | 디스크 기반                                   | 메모리 기반                                                |
| 처리 속도    | 느림 (디스크 I/O 발생)                        | 빠름 (메모리 캐싱 활용)                                     |
| 처리 방식    | 배치 처리 (Batch Processing)                  | 배치 + 스트리밍 + 실시간 처리 가능                           |
| 구성 요소    | HDFS, YARN, MapReduce                         | Spark Core, Spark SQL, Spark Streaming, MLlib 등             |
| 개발 언어    | Java 중심                                    | Scala, Python, Java, R 등 다양한 언어 지원                   |
| 작업 유형    | 주로 배치 처리                                | 실시간 분석, 머신러닝, 스트리밍 처리 등 다양한 활용 가능       |
| 데이터 형식  | Key-Value 기반 비정형 데이터 처리에 적합        | 구조화 데이터(DataFrame), 비정형 데이터(RDD) 모두 처리 가능   |
| 데이터 복구  | 복제본 기반의 데이터 복구                     | RDD 계보를 통한 복구                                         |

---

### Hadoop의 주요 단점 및 Spark 대비 개선점

1. **디스크 기반 처리 속도 저하**  
   - Hadoop: 디스크 기반 처리로 I/O 병목  
   - Spark: 메모리 기반 처리로 속도 향상  

2. **실시간 처리 한계**  
   - Hadoop: 배치 처리 전용  
   - Spark: Spark Streaming을 통해 실시간 처리 지원  

3. **복잡한 개발 환경**  
   - Hadoop: MapReduce 기반 코드가 복잡하고 장황  
   - Spark: 고수준 API로 코드 간결성 증가  

4. **자원 관리 한계**  
   - Hadoop: YARN을 통한 자원 관리 개선 (여전히 복잡)  
   - Spark: 드라이버 프로그램을 통해 효율적 자원 관리  
