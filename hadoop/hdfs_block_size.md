
# HDFS Block Size 정리

## Block Size란?
- HDFS 에서 "파일을 저장할 때 쪼개는 기본 단위 크기"
- 하나의 파일이 여러 개 블록으로 나뉘어 저장된다.
- HDFS에서는 보통 128MB 또는 256MB가 기본 블록 크기이다. (버전에 따라 기본 크기가 다름)

## 왜 필요할까?
- 파일을 통째로 하나의 서버에 저장하면 크기 제한, 장애 문제가 생긴다.
  - 참고: hdfs에서 파일의 블록은 하나의 노드에만 존재하는게 아니고 여러 노드에 분산되어 있다. (NameNode는 위치 정보만 제공)
- 큰 파일도 여러 블록으로 나누어 여러 서버에 분산 저장한다.
- 서버 하나에만 파일이 저장돼 있다면 그 서버에 문제가 생기면 파일을 유실할 수 있다.
- 여러 서버로 나눠서 저장하면 부하를 분산할 수 있다.
  - 병렬처리에도 좋음

---

## Block size 크기에 따른 영향에 대해 알아보자 

### Block Size가 클 때

#### 장점
- 메타데이터 관리 효율적 → 블록 수 감소 → NameNode 메모리 부담 감소
- 대용량 파일 읽기 효율 → 디스크 I/O 줄어듦 (큰 블록 단위 연속 읽기)
- 맵리듀스 작업 수 감소 → Task 수 줄어 Job 오버헤드 감소 (작업 시작 빨라짐)

### 단점
- 작은 파일 비효율 → 작은 파일도 큰 블록 공간 낭비 (Storage Waste)
  - 예를 들어, 실제 파일은 1MB인데 Block size는 256MB 라면 블록 공간이 낭비 된다.
- 병렬 처리 한계 → 블록 수가 적어 Task 병렬 실행 수 줄어듦

### Block Size가 작을 때

#### 장점
- 작은 파일 병렬 처리 유리 → 블록이 많아져서 Task 수 증가 → 병렬성 향상
- 작은 데이터 빠른 부분 읽기 가능 → 필요한 부분만 읽을 수 있음

#### 단점
- NameNode 메모리 부담 증가 → 블록 메타데이터 많아져 메모리 소모 커짐
- 디스크 I/O 증가 → 파일 읽을 때 블록을 넘나드는 비용 증가
- 맵리듀스 오버헤드 증가 → Task 수 많아져 스케줄링 부하 커짐

#### 요약

| Block Size | 장점 | 단점 |
|:---|:---|:---|
| 크다 | 메타데이터 효율, 대용량 파일 최적화 | 작은 파일 비효율, 병렬성 저하 |
| 작다 | 작은 파일 병렬 처리, 부분 읽기 최적화 | 메타데이터 과부하, 디스크 I/O 증가 |

#### 결론

- **대용량 파일 위주**  
  → 블록 크기 크게 설정 (128MB, 256MB, 512MB)
- **작은 파일 많을 때**  
  → 기본값 유지 (128MB) + 작은 파일 자체를 줄이는 방식(합치기) 권장

---

## Block size 설정 가이드라인

- 기본값: **128MB** (Hadoop 2.x 이후)
- 수 GB~TB급 대용량 파일: **256MB ~ 512MB 추천**
  - 용량이 클 경우 block size도 크게하여 NameNode 메모리 절약, 메타데이터 관리 효율 향상
  - 작은 블록 여러 개를 읽는 것보다 큰 블록을 몇 번만 읽는 게 디스크 I/O 오버헤드가 줄어든다.
  - MapReduce, Spark 작업 시 **Block size마다 Task가 생기는데** Block이 많을 경우 Task 오버헤드가 발생한다.
- 작은 파일이 많은 경우: **128MB 유지**  
  - 단, 이 때도 작은 파일 줄이기 권장
- 논리 Block size와 물리 Block size가 조금씩 다를 수 있으니 너무 딱맞게 Block size를 지정하는 것은 피하자

### 상황별 권장 블록 크기

| 상황 | 권장 블록 크기 | 이유 |
|:---|:---|:---|
| 수백 MB ~ 수 GB 파일 위주 | 128MB | 기본값으로 충분, 오버헤드 없음 |
| 수 GB ~ 수십 GB 파일 위주 | 256MB ~ 512MB | 블록 수 줄여 NameNode 메모리 절약, I/O 최적화 |
| TB급 초대형 파일 다수 | 512MB 이상 | NameNode 안정성 확보 위해 블록 수 극단적으로 줄임 |
| 매우 많은 작은 파일 | 64MB 이하 가능 (권장X) | 블록 크기 줄이기보단 파일 합치기 권장 |

### 추가 팁

- MapReduce, Spark 작업 많으면 → 블록 크기 약간 키우는 게 유리 (Task 오버헤드 줄이기)
- NameNode 메모리 사용량 계산  
  → 블록 1개당 약 150~250바이트 메타데이터 사용

**예시:**  
블록 100억 개 → NameNode 약 25GB 메모리 필요

---

## 핵심 요약

- **큰 파일 많으면 블록도 크게**
- **작은 파일 많으면 기본값 유지하고, 파일 합치기**
