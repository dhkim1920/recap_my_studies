# Iceberg 테이블의 파티션 처리 및 파일 생성 전략

## 파티션 지정 시 동작

- `PARTITIONED BY (days(time))`처럼 파티션을 지정하면, Spark는 각 파티션 값마다 하나의 디렉토리로 그룹핑하여 데이터를 저장한다.
- 예: `time=2025-06-01`, `time=2025-06-02`와 같은 디렉토리 생성
- 각 디렉토리에는 Spark가 파일을 하나 또는 몇 개만 생성하려고 하므로, 결과적으로 **파티션 하나당 큰 파일이 생성된다.**

## Unpartitioned

- 파티션 없이 테이블을 생성하면, Spark는 전체 데이터를 대상으로 병렬로 write 수행
- 데이터가 분산되며 여러 Executor가 동시에 여러 파일을 생성하므로, **더 많은 수의 작은 파일이 생성된다.**

## Spark 쓰기 전략 비교

| 조건           | 쓰기 방식       | 결과                        |
|----------------|-------------|-----------------------------|
| Unpartitioned  | 전체 병렬 write | 파일 수 많고 작게 쪼개짐    |
| Partitioned    | 파티션 별 write | 각 파티션에 큰 파일 생성됨  |

## 4. 파일 크기 조정 방법

설정을 통해 조절 가능:

```scala
spark.conf.set("spark.sql.files.maxRecordsPerFile", 500000)
```

또는 명시적으로 파티션 수 지정:

```scala
df.repartition(100).writeTo("catalog.db.table").append()
```

## 결론

- Iceberg에서 파티션을 지정하면 Spark는 파티션 단위로 파일을 생성하여 **상대적으로 큰 파일**이 생성된다.
- 파티션이 없으면 전체 데이터를 병렬로 처리하면서 **작은 파일이 많이 생성된다.**
- 이는 Spark의 기본적인 쓰기 전략에 따른 것이며, 설정 조정이나 `repartition`으로 제어 가능하다. 

> 엔진이 다를 경우 어떻게될까?? 이건 나중에 확인이 필요
