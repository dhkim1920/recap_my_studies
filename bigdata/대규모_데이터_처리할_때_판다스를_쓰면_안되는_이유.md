# 대규모 데이터 처리할 때 판다스를 쓰면 안되는 이유

본 문서는 대규모 데이터 Batch 처리 시 발생하는 Pandas의 구조적 한계와, 최신 버전(Pandas 3.0+)에서 개선된 사항을 기술적인 관점에서 정리합니다.

---

## 주요 성능 저하 요인 및 기술 검증

### 단일 스레드/코어 기반 동작 (GIL의 한계)

- **원인:** Python의 **GIL**로 인해 한 번에 하나의 스레드만 실행 가능하다. Pandas의 고수준 연산은 C/C++로 구현되어 이를 일부 우회하지만, `apply`, `map` 등 사용자 정의 함수가 개입하면 즉시 단일 코어만 사용한다.

### 파이썬 루프와 직렬화 오버헤드

- **원인:** `iterrows()` 등 행 단위 순회는 매 반복마다 Pandas Series 객체를 생성하는 막대한 오버헤드를 발생시킨다.
- **기술적 차이:** Vectorization 연산은 CPU의 **SIMD(Single Instruction, Multiple Data)** 명령어를 통해 여러 데이터를 한꺼번에 처리하지만, 루프 방식은 파이썬 인터프리터가 매번 개입하여 수백 배 이상 느려지게 할수 있다.

### 메모리 집약적 구조 (In-Memory)

- **원인:** Pandas는 전체 데이터를 RAM에 상주시켜야 하는 **In-memory** 구조이다. 원본 데이터 크기의 **5~10배**에 달하는 RAM이 확보되어야 안정적인 처리가 가능하디. 
- **현상:** K8s와 같은 컨테이너 환경에서 `Memory Limit`에 도달할 경우, 커널은 즉시 **OOM Kill**하거나 심각한 성능 저하를 유발

### 비효율적인 데이터 복사 (Copy-heavy)

- **개선사항:** 과거 버전에서는 데이터 필터링이나 슬라이싱 시 불필요한 사본이 생성되어 메모리 낭비가 심했다고 한다.
- **Pandas 3.0부터 Copy-on-Write(CoW)가 기본값**으로 적용됩니다. 실제 데이터가 수정되기 전까지는 원본을 공유하므로, 메모리 효율이 이전 세대 대비 비약적으로 향상되었다.

### Object Type의 오버헤드

- **원인:** 기존 `object` 타입은 메모리 여기저기 흩어진 파이썬 객체의 포인터 집합으로, CPU 캐시 효율이 매우 좋지 않았다.
- Pandas 3.0은 **Apache Arrow 기반의 String 타입**을 기본으로 채택, 데이터를 연속된 메모리에 배치하여 메모리 파편화를 해결하고 처리 속도를 크게 높였다.


---

## 대용량 데이터 처리를 위한 권장 사항

1. **엔진 교체 검토:** 대규모 연산 시, Rust 기반으로 멀티 스레드를 기본 지원하는 **Polars**나 **PyArrow**를 직접 활용하는 것이 유리
2. **직렬화 가속:** CSV 출력 시 `engine='pyarrow'` 옵션을 활성화하여 멀티 코어로 직렬화를 수행행
3. **데이터 타입 명시:** 로드 시점부터 `dtype`을 명시하여 `object` 타입 생성을 최소화하고 메모리 점유율을 낮추자
4. **Chunk 처리:** 메모리 부족이 우려될 경우 `read_csv(..., chunksize=N)`를 사용하여 데이터를 분할 처리하는 스트리밍 방식을 권장
